{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7fc6c80afb10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "from datetime import datetime\n",
    "\n",
    "from com.yahoo.ml.tf import TFCluster\n",
    "import mnist_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-i\", \"--images\", help=\"HDFS path to MNIST images in parallelized format\")\n",
    "parser.add_argument(\"-f\", \"--format\", help=\"example format: (csv|pickle|tfr)\", choices=[\"csv\",\"pickle\",\"tfr\"], default=\"csv\")\n",
    "parser.add_argument(\"-l\", \"--labels\", help=\"HDFS path to MNIST labels in parallelized format\")\n",
    "parser.add_argument(\"-m\", \"--model\", help=\"HDFS path to save/load model during train/test\", default=\"mnist_model\")\n",
    "parser.add_argument(\"-o\", \"--output\", help=\"HDFS path to save test/inference output\", default=\"predictions\")\n",
    "parser.add_argument(\"-r\", \"--readers\", help=\"number of reader/enqueue threads\", type=int, default=1)\n",
    "parser.add_argument(\"-s\", \"--steps\", help=\"maximum number of steps\", type=int, default=1000)\n",
    "parser.add_argument(\"-X\", \"--mode\", help=\"train|test\", default=\"train\")\n",
    "parser.add_argument(\"-tb\", \"--tensorboard\", help=\"launch tensorboard process\", action=\"store_true\")\n",
    "args = parser.parse_args(['-f', 'csv', '-m', 'mnist_model', '-r', '1', '-i', 'mnist/csv/train/images', '-l', 'mnist/csv/train/labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(format='csv', images='mnist/csv/train/images', labels='mnist/csv/train/labels', mode='train', model='temp_model', output='predictions', readers=1, steps=1000, tensorboard=False)\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = sc.textFile(args.images).map(lambda ln: [int(x) for x in ln.split(',')])\n",
    "labels = sc.textFile(args.labels).map(lambda ln: [float(x) for x in ln.split(',')])\n",
    "\n",
    "dataRDD = images.zip(labels)\n",
    "dataRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_executors = int(sc._conf.get(\"spark.executor.instances\"))\n",
    "cluster = TFCluster.reserve(sc, num_executors, 1, True, TFCluster.InputMode.SPARK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'addr': ('gpbl191n10.blue.ygrid.yahoo.com', 38252), 'task_index': 0, 'port': 32974, 'authkey': UUID('dcafb079-8675-4984-8bbc-7e4f0e47c996'), 'worker_num': 0, 'host': 'gpbl191n10.blue.ygrid.yahoo.com', 'ppid': 122387, 'job_name': 'ps', 'tb_port': 0}\n",
      "{'addr': '/tmp/pymp-JxxA_1/listener-IJlOe1', 'task_index': 0, 'port': 47690, 'authkey': UUID('9cf395ef-9c23-4467-a236-06e70522a465'), 'worker_num': 1, 'host': 'gpbl191n10.blue.ygrid.yahoo.com', 'ppid': 122261, 'job_name': 'worker', 'tb_port': 35200}\n",
      "{'addr': '/tmp/pymp-sUbkvF/listener-S9WrOv', 'task_index': 1, 'port': 51928, 'authkey': UUID('af3fc0a7-358a-43e9-9b12-ca859feda768'), 'worker_num': 2, 'host': 'gpbl191n10.blue.ygrid.yahoo.com', 'ppid': 122265, 'job_name': 'worker', 'tb_port': 0}\n",
      "{'addr': '/tmp/pymp-dLO3XF/listener-qmKXZe', 'task_index': 2, 'port': 45604, 'authkey': UUID('5f448d57-954a-4c7b-9044-0975d8e6842d'), 'worker_num': 3, 'host': 'gpbl191n15.blue.ygrid.yahoo.com', 'ppid': 143944, 'job_name': 'worker', 'tb_port': 0}\n"
     ]
    }
   ],
   "source": [
    "for node in cluster.cluster_info:\n",
    "  print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster.start(mnist_dist.map_fun, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster.train(dataRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to ('gpbl191n18.blue.ygrid.yahoo.com', 51157), c4babd7c-aa69-4232-9c85-7be46c83c4be\n"
     ]
    }
   ],
   "source": [
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# cluster = TFCluster.reserve(sc, num_executors, num_ps, True, TFCluster.InputMode.SPARK)\n",
    "# args.mode = \"test\"\n",
    "# cluster.start(mnist_dist.map_fun, args)\n",
    "# resultRDD = cluster.test(dataRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# resultRDD.first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
